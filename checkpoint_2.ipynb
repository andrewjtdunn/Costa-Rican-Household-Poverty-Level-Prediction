{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andrew Dunn, Katherine Dumais, Kathryn Link-Oberstar, Lee-Or Bentovim\n",
    "# Summary of initial feature engineering and model testing for checkpoint 2\n",
    "\n",
    "# This analysis runs after we load, clean, and generate additional variables in load_data.py, \n",
    "# and initially explored the data in exploratory_analysis.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, recall_score, classification_report\n",
    "import load_data as ld\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler, SVMSMOTE\n",
    "\n",
    "df, X_valid, y_valid = ld.load_train_data()\n",
    "\n",
    "cols_to_drop = ['Id', 'idhogar', 'rez_esc']\n",
    "\n",
    "#Data Cleaning\n",
    "for dfs in [df, X_valid, y_valid]:\n",
    "    dfs.replace([np.inf, -np.inf], np.nan, inplace=True) # Written by Kathryn Link-Oberstar \n",
    "    for col in cols_to_drop:\n",
    "        if col in dfs.columns:\n",
    "            dfs.drop(col, axis=1, inplace=True)\n",
    "    dfs.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**\n",
    "\n",
    "We generate several new variables, derived from our literature review, in load_data.py:\n",
    "\n",
    "- max_education_level: the education level of the person with the highest education level in the household\n",
    "- hh_has_marriage: whether someone in the household is married\n",
    "- hh_max_age: the age of the oldest person in the household\n",
    "- hh_sex_ratio: the ratio of men to women in the household\n",
    "- hh_child_woman_ratio_12: the ratio of children to women in the household, with children defined as being under 12\n",
    "- hh_child_adult_ratio_12: the ratio of children to adults in the household, with children defined as being under 12\n",
    "- hh_child_woman_ratio_19: the ratio of children to women in the household, with children defined as being under 19\n",
    "- hh_child_adult_ratio_19: the ratio of children to adults in the household, with children defined as being under 19\n",
    "- v2a1_log: the logged value of v2a1, the monthly rent payment. We also estimate and impute values into v2a1 when that field is missing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Testing**\n",
    "\n",
    "We tested variations of four different models: random forest, naive bayes, KNN, and logistic regression in the following notebooks:\n",
    "\n",
    "Below, we demonstrate the best performing variants of those models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Logistic Regression*\\\n",
    "The goal of logistic regression is to find the best parameters of a logistic function that minimizes the difference between the predicted probabilities and the actual outcomes. The logistic function uses the sigmoid function, which maps any real number into a range between 0 and 1, allowing us to interpret the output as a probability. The input features are weighted and combined linearly, and the resulting value is passed through the logistic function to produce a probability. We then use gradient descent to determine what the best classification is for these categories. Regularization helps to improve the generalization performance of the model by balancing the bias-variance trade-off and reducing overfitting.  By penalizing the weights of the input features, regularization encourages the model to focus on the most important features that are most relevant to the target variable. Overfitting occurs when a model learns to fit the training data too closely, including noise and irrelevant features, leading to poor generalization performance on new, unseen data. In this case we will try L2 regularization which adds a penalty term proportional to the square of the weights.\n",
    "\n",
    "One drawback however, is that it assumes linear relationships which based on the diversity of our data, may not be true in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "X = df.iloc[: , :-1]\n",
    "y = df.loc[:, 'Target']\n",
    "## Will remove once we decide on final value \n",
    "def evaluate_classification(y_pred, y_true = y_valid, labels=[1,2,3,4], cm = False):\n",
    "    '''\n",
    "    Written by Kathryn Link- Oberstar \n",
    "    '''\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "    if cm is True:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "sm = SVMSMOTE(random_state=42)\n",
    "\n",
    "#Train our data with two oversampling methods: SVM SMOTE and random sampling with replacement \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_df_resampled, train_y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "sm = SVMSMOTE(random_state=42)\n",
    "X_smote, y_smote = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"With Smote- RFE\")\n",
    "#Recursive feature elimination\n",
    "rfe = RFE(estimator=LogisticRegression(solver='liblinear', penalty='l2'),n_features_to_select = 5, step = 1)\n",
    "rfe.fit(X_smote, y_smote)\n",
    "y_pred = reg.predict(X_valid)\n",
    "evaluate_classification(y_pred, y_true = y_valid, labels=[1,2,3,4], cm = True)\n",
    "\n",
    "X_train.iloc[:,[138, 126, 127, 108, 107]]\n",
    "\n",
    "print(\"With Random Selection- RFE\")\n",
    "#Recursive feature elimination\n",
    "rfe = RFE(estimator=LogisticRegression(solver='liblinear', penalty='l2'),n_features_to_select = 5, step = 1)\n",
    "rfe.fit(train_df_resampled, train_y_resampled)\n",
    "y_pred = reg.predict(X_valid)\n",
    "evaluate_classification(y_pred, y_true = y_valid, labels=[1,2,3,4], cm = True)\n",
    "\n",
    "\n",
    "print(\"With Smote- Variance Threshold\")\n",
    "# get rid of features without a lot of variance \n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "a= X_smote.copy()\n",
    "rev_x = sel.fit_transform(a)\n",
    "reg = LogisticRegression(solver='liblinear', penalty='l2').fit(rev_x, y_smote)\n",
    "\n",
    "y_pred = reg.predict(sel.transform(X_valid.copy()))\n",
    "evaluate_classification(y_pred, y_true = y_valid, labels=[1,2,3,4], cm = True)\n",
    "\n",
    "print(\"With Random Selection-Variance threshold\")\n",
    "\n",
    "# get rid of features without a lot of variance \n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "rev_x = sel.fit_transform(train_df_resampled.copy())\n",
    "reg = LogisticRegression(solver='liblinear', penalty='l2').fit(rev_x, train_y_resampled)\n",
    "a= X_valid.copy()\n",
    "y_pred = reg.predict(sel.transform(a))\n",
    "evaluate_classification(y_pred, y_true = y_valid, labels=[1,2,3,4], cm = True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While, if we reference the logistic regression function, without overweighting we only classify the majority class 4 (please see regression document). With overweighting and feature selection methods, we get our best predictors using regularized logistic regression in terms of classification accuracy and F1 score. But given the diversity of the results, it is clear feature selection as opposed to logistic regression usage is the most important part of this work. It is unclear if regularized logistic regression will be the best indicator going forward."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Discussion **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
