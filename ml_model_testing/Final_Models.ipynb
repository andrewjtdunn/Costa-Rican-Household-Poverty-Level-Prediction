{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data & Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import ComplementNB, GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "import os\n",
    "import analyze_k\n",
    "SEED = 12\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "import load_data as ld\n",
    "df, train_indices, valid_indices= ld.load_train_data()\n",
    "from evaluate_classification import evaluate_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evaluate_classification import evaluate_classification\n",
    "import loops\n",
    "\n",
    "df, train_indices, valid_indices = ld.load_train_data(filepath = 'Kaggle_download/train.csv')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd \"/Users/andrewdunn/Desktop/Classes/UChicago/\"CAPP 30254 - Machine Learning\"/Costa-Rican-Household-Poverty-Level-Prediction/ml_model_testing\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of the Box"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = ComplementNB()\n",
    "nb_results = loops.loop_model(nb, df, train_indices, valid_indices, inc_cm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_nb = analyze_k.average_outcome(nb_results)\n",
    "avg_nb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "knn_results = loops.loop_model(knn, df, train_indices, valid_indices, inc_cm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_knn = analyze_k.average_outcome(knn_results)\n",
    "avg_knn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state = SEED)\n",
    "clf_results = loops.loop_model(clf, df, train_indices, valid_indices, inc_cm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_clf = analyze_k.average_outcome(clf_results)\n",
    "avg_clf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear', penalty='l2')\n",
    "lr_results = loops.loop_model(lr, df, train_indices, valid_indices, inc_cm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lr = analyze_k.average_outcome(lr_results)\n",
    "avg_lr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = ComplementNB()\n",
    "nb_results = loops.loop_model(nb, df, train_indices, valid_indices, oversample=ld.gen_SMOTE_data, var_thresh=False, scaler=scaler, inc_cm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_nb = analyze_k.average_outcome(nb_results)\n",
    "avg_nb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "knn_results = loops.loop_model(knn, df, train_indices, valid_indices, scaler=scaler, var_thresh=True, inc_cm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_knn = analyze_k.average_outcome(knn_results)\n",
    "avg_knn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to its value in Random_Forest, where extensive testing occurred\n",
    "SEED = 0\n",
    "\n",
    "os_clf = make_pipeline(RandomOverSampler(random_state=SEED),\n",
    "                        RandomForestClassifier(random_state = SEED,\n",
    "                                               n_estimators = 600,\n",
    "                                                min_samples_split = 5,\n",
    "                                                min_samples_leaf = 4,\n",
    "                                                max_features = 'auto',\n",
    "                                                max_depth = 10,\n",
    "                                                bootstrap = True))\n",
    "\n",
    "\n",
    "clf_results = loops.loop_model(os_clf, df, train_indices, valid_indices, scaler=scaler, var_thresh=True, inc_cm=False)\n",
    "analyze_k.average_outcome(clf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change seed back to original value\n",
    "SEED = 12\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(solver='liblinear', penalty='l2')\n",
    "results = loops.loop_model(reg,df,train_indices,valid_indices,oversample=ld.gen_SMOTE_data,var_thresh=True)\n",
    "avg = analyze_k.average_outcome(results)\n",
    "avg\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Stage Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"Target\")\n",
    "y = df.loc[:, 'Target']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "train_df_resampled, train_y_resampled = ld.gen_oversample_data(train, seed = 12)\n",
    "X_smote, y_smote = ld.gen_SMOTE_data(train, seed = 12)\n",
    "\n",
    "\n",
    "def Two_stage(model1, model2):\n",
    "    #Fit First Layer\n",
    "    reg=model1.fit(X_smote, y_smote)\n",
    "    y_pred = reg.predict(X_valid)\n",
    "   \n",
    "    #Take first layer predictions and get rid of obs we predicted\n",
    "    #4 on in test set\n",
    "    y_pred= pd.DataFrame(y_pred, columns=[\"pred\"])\n",
    "    a= pd.concat([X_valid.reset_index(drop=True), y_pred], axis=1)\n",
    "    new_test_set= a.loc[a.loc[:,\"pred\"]!= 4,:]\n",
    "\n",
    "    #Run Layer 2 on non-4 obs\n",
    "    rev_dataset=pd.concat([X_smote, y_smote], axis=1)\n",
    "    rev_dataset= rev_dataset.loc[rev_dataset.loc[:,\"Target\"]!= 4, :]\n",
    "    Y= rev_dataset.loc[:,\"Target\"]\n",
    "    X= rev_dataset.drop(columns=\"Target\")\n",
    "    reg= model2.fit(X, Y)\n",
    "\n",
    "    #run fit on revised test set\n",
    "    new_pred = reg.predict(new_test_set.drop(columns=\"pred\"))\n",
    "    #combine predictions\n",
    "    a.loc[a.loc[:,\"pred\"]!= 4,\"pred\"]=new_pred\n",
    "    #evaluate\n",
    "    evaluate_classification(a.loc[:,\"pred\"], y_true = y_valid, l=[1,2,3,4], cm = True)\n",
    "\n",
    "os_clf = make_pipeline(RandomOverSampler(random_state=0),\n",
    "                        RandomForestClassifier(random_state = 0,\n",
    "                                               n_estimators = 600,\n",
    "                                                min_samples_split = 5,\n",
    "                                                min_samples_leaf = 4,\n",
    "                                                max_features = 'auto',\n",
    "                                                max_depth = 10,\n",
    "                                                bootstrap = True))\n",
    "\n",
    "\n",
    "Two_stage(LogisticRegression(solver='liblinear', penalty='l2'),os_clf)\n",
    "Two_stage(os_clf,LogisticRegression(solver='liblinear', penalty='l2'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode target classes in the DataFrame\n",
    "bin_df = df.copy()\n",
    "bin_df['Target'] = bin_df['Target'].replace({1: 1, 2: 1, 3: 0, 4: 0})\n",
    "\n",
    "X_train = bin_df.drop(columns=\"Target\")\n",
    "y_train = bin_df.loc[:, 'Target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_results = loops.loop_model(nb, bin_df, train_indices, valid_indices, scaler=scaler, inc_cm=True)\n",
    "analyze_k.average_outcome(nb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_nb = analyze_k.average_outcome(nb_results)\n",
    "avg_nb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_results = loops.loop_model(clf, bin_df, train_indices, valid_indices, scaler=scaler, inc_cm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_clf = analyze_k.average_outcome(clf_results)\n",
    "avg_clf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = loops.loop_model(knn, bin_df, train_indices, valid_indices, scaler=scaler, inc_cm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_knn = analyze_k.average_outcome(knn_results)\n",
    "avg_knn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(solver='liblinear', penalty='l2')\n",
    "results = loops.loop_model(reg,bin_df,train_indices,valid_indices,oversample=ld.gen_SMOTE_data,var_thresh=True)\n",
    "avg = analyze_k.average_outcome(results)\n",
    "avg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Stage Binary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Standardize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Stage 1: create a binary target separating classes 1/2 from 3/4\n",
    "y_train_binary = y_train.copy()\n",
    "y_train_binary[y_train_binary.isin([1, 2])] = 1\n",
    "y_train_binary[y_train_binary.isin([3, 4])] = 0\n",
    "\n",
    "# Fit the first model\n",
    "model_1_2_vs_3_4 = ComplementNB()\n",
    "model_1_2_vs_3_4.fit(X_train_scaled, y_train_binary)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = model_1_2_vs_3_4.predict(X_test_scaled)\n",
    "evaluate_classification(y_pred, y_test)\n",
    "\n",
    "# Stage 2: separate class 1 from class 2\n",
    "mask_1_2 = y_train_binary == 1\n",
    "model_1_vs_2 = ComplementNB()\n",
    "model_1_vs_2.fit(X_train_scaled[mask_1_2], y_train[mask_1_2])\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = model_1_vs_2.predict(X_test_scaled)\n",
    "evaluate_classification(y_pred, y_test)\n",
    "\n",
    "# Stage 3: separate class 3 from class 4\n",
    "mask_3_4 = y_train_binary == 0\n",
    "model_3_vs_4 = ComplementNB()\n",
    "model_3_vs_4.fit(X_train_scaled[mask_3_4], y_train[mask_3_4])\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = model_3_vs_4.predict(X_test_scaled)\n",
    "evaluate_classification(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capp-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
