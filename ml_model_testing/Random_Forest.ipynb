{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model for Costa Rican Poverty Level Predicion\n",
    "Written by: Andrew Dunn\n",
    "\n",
    "### Outline of Notebook\n",
    "**[1. Project Set-Up](#project-set-up)** \\\n",
    "*[1.1 Load Packages and Data](#1.1-load-packages-and-data)* \\\n",
    "*[1.2 Prep the data](#1.2-prep-the-data)* \\\n",
    "\\\n",
    "**[2. What is a Random Forest Model?](#2.-model-testing)** \\\n",
    "*[2.1 Summary of Approach](#2.1-summary-of-approach)* \\\n",
    "*[2.2 Summary of Findings](#2.2-summary-of-findings)* \\\n",
    "\\\n",
    "**[3. Models](#3.-models)** \\\n",
    "*[3.1 Conduct Random Search Cross Validation](#3.1-conduct-random-search-cross-validation)* \\\n",
    "*[3.2 Conduct Random Search Cross Validation on Resampled Data](#3.2-conduct-random-search-cross-validation-on-resampled-data)* \\\n",
    "*[3.3 Conduct Random Search Cross Validation on SMOTE data](#3.3-conduct-random-search-cross-validation-on-smote-data)* \\\n",
    "\\\n",
    "**[4. Limitations and Next Steps](#4.-limitations-and-next-steps)** \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Set-Up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the working directory\n",
    "%cd ..\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, recall_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler, SVMSMOTE\n",
    "from collections import Counter\n",
    "import pprint\n",
    "\n",
    "import load_data\n",
    "from evaluate_classification import evaluate_classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "df, X_valid, y_valid = load_data.load_train_data()\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.loc[:, 'Target']\n",
    "\n",
    "# Create oversampled dataframes\n",
    "train_X_resampled, train_y_resampled = load_data.gen_oversample_date(df)\n",
    "X_smote, y_smote = load_data.gen_SMOTE_data(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is a Random Forest Model?\n",
    "\n",
    "A Random Forest model is a machine learning algorithm that creates many decision trees and averages the results from them. Because of this, random forests have the benefit over decision trees of being less likely to overfit on the training data. They are frequently used for classification questions. \n",
    "\n",
    "We apply this to our Target column, which has values 1-4, representing the different levels of poverty."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Summary of Approach\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run random search cross validation on three different sets of data: \n",
    "- the raw cleaned data\n",
    "- data where we randomly oversample from the underrepresented classes\n",
    "- data where we apply the SMOTE methodology to generate additional rows for the underrepresented classes\n",
    "\n",
    "\n",
    "The random search cross validation process randomly selects different combinations of hyperparameters and returns the best fitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Summary of Findings\n",
    "\n",
    "Thus far, there is no significant difference between the models run on the different datasets. The best performing models from the random search cross validation process yields an accuracy of about .65 and an f1 score of about .59 when run on the validation data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Models\n",
    "\n",
    "### 3.1 Basic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of default model\n",
    "clf = RandomForestClassifier(random_state= SEED)\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_pred = clf.predict(X_valid)\n",
    "evaluate_classification(y_pred, y_valid, cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make graph of feature importance\n",
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "feature_names = X.columns.values.tolist()\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "# top 20 features\n",
    "top_20 = forest_importances.nlargest(20)\n",
    "indices = np.where(np.in1d(forest_importances, top_20))[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "top_20.plot.bar(yerr=std[indices], ax=ax)\n",
    "\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test number of trees in forest\n",
    "#num_trees = [100, 200, 300, 400, 500, 1000, 1500, 2000]\n",
    "num_trees = [i for i in range(100, 2100, 100)]\n",
    "accuracy_lst = []\n",
    "f1_lst = []\n",
    "recall_lst_1 = []\n",
    "recall_lst_2 = []\n",
    "recall_lst_3 = []\n",
    "recall_lst_4 = []\n",
    "\n",
    "for i in num_trees:\n",
    "    clf = RandomForestClassifier(n_estimators = i,\n",
    "                                random_state = SEED)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "\n",
    "    accuracy, f1, recall = evaluate_classification(y_pred, y_valid, return_vals = True)\n",
    "    \n",
    "    accuracy_lst.append(accuracy)\n",
    "    f1_lst.append(f1)\n",
    "    recall_lst_1.append(recall[0])\n",
    "    recall_lst_2.append(recall[1])\n",
    "    recall_lst_3.append(recall[2])\n",
    "    recall_lst_4.append(recall[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the stats\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,10))\n",
    "\n",
    "plt.plot(num_trees, accuracy_lst, label = 'accuracy', color = 'blue')\n",
    "plt.plot(num_trees, f1_lst, label = 'f1', color = 'red')\n",
    "plt.plot(num_trees, recall_lst_1, label = 'recall_1', color = 'darkgreen')\n",
    "plt.plot(num_trees, recall_lst_2, label = 'recall_2', color = 'green')\n",
    "plt.plot(num_trees, recall_lst_3, label = 'recall_3', color = 'forestgreen')\n",
    "plt.plot(num_trees, recall_lst_4, label = 'recall_4', color = 'seagreen')\n",
    "\n",
    "\n",
    "\n",
    "ax.legend(loc=\"lower right\", fontsize=16)\n",
    "ax.set_xlabel(\"number of trees\", fontsize=16)\n",
    "ax.set_ylabel(\"performance stats\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Conduct Random Search Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look via randomized search on the raw cleaned data\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "               \n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state= SEED)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = clf, \n",
    "                                param_distributions = random_grid, \n",
    "                                n_iter = 100, \n",
    "                                cv = 3, \n",
    "                                verbose = 2,\n",
    "                                 random_state= SEED, \n",
    "                                 n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X, y)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best random model\n",
    "best_random = rf_random.best_estimator_\n",
    "best_random.fit(X, y)\n",
    "y_pred = best_random.predict(X_valid)\n",
    "evaluate_classification(y_pred, y_valid, cm = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Conduct Random Search Cross Validation on Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on the resampled data\n",
    "clf = RandomForestClassifier(random_state= SEED)\n",
    "\n",
    "rf_rs_random = RandomizedSearchCV(estimator = clf, \n",
    "                                param_distributions = random_grid, \n",
    "                                n_iter = 100, \n",
    "                                cv = 3, \n",
    "                                verbose = 2,\n",
    "                                 random_state= SEED, \n",
    "                                 n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_rs_random.fit(train_X_resampled, train_y_resampled)\n",
    "\n",
    "rf_rs_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best random model on randomly resampled data\n",
    "best_rs_random = rf_rs_random.best_estimator_\n",
    "best_rs_random.fit(X, y)\n",
    "y_pred = best_rs_random.predict(X_valid)\n",
    "evaluate_classification(y_pred, y_valid, cm = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Conduct Random Search Cross Validation on SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on the SMOTE data\n",
    "clf = RandomForestClassifier(random_state= SEED)\n",
    "\n",
    "rf_smote_random = RandomizedSearchCV(estimator = clf, \n",
    "                                param_distributions = random_grid, \n",
    "                                n_iter = 100, \n",
    "                                cv = 3, \n",
    "                                verbose = 2,\n",
    "                                random_state= SEED, \n",
    "                                n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_smote_random.fit(X_smote, y_smote)\n",
    "\n",
    "rf_smote_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best random model on randomly resampled data\n",
    "best_smote_random = rf_smote_random.best_estimator_\n",
    "best_smote_random.fit(X, y)\n",
    "y_pred = best_smote_random.predict(X_valid)\n",
    "evaluate_classification(y_pred, y_valid, cm = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Limitations and Next Steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis only initially examines different random forest models. Further attention should be paid to the data preprocessing and feature generation to ensure that the data inputs are as high quality and possible. The models clearly do well at predicted label #4, but appear to do a worse job of categorizing the other labels. \n",
    "\n",
    "Next steps include further testing of different versions of this random forest models and different combinations of hyperparamters, as well as examining if there are ways to better categorize the labels other than 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
